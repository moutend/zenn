---
title: "ï¼ˆSwiftï¼‰æ©Ÿæ¢°å­¦ç¿’ã‚’åˆ©ç”¨ã—ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†é¡ã™ã‚‹"
emoji: "ğŸ—‚"
type: "tech"
topics: [Apple, Swift, "Core ML", æ©Ÿæ¢°å­¦ç¿’]
published: true
---
## ã¯ã˜ã‚ã«

ã“ã®è¨˜äº‹ã§ã¯Appleã®æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯Core MLã‚’åˆ©ç”¨ã—ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è­˜åˆ¥ã™ã‚‹æ‰‹é †ã‚’è§£èª¬ã—ã¾ã™ã€‚ä¾‹ãˆã°äººã®å£°ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ãŸã‚‰`speech`ã€éŸ³æ¥½ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ãŸã‚‰`music`ã«åˆ†é¡ã—ã¾ã™ã€‚

ã¨ã„ã£ã¦ã‚‚ã€é›£ã—ã„è¦ç´ ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚Appleã¯è¨“ç·´æ¸ˆã¿ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã—ã¦ã„ã‚‹ã®ã§ã€ãã‚Œã‚’åˆ©ç”¨ã—ã¾ã™ã€‚è¬ã‚ã„ãŸæ•°å¼ãŒç™»å ´ã™ã‚‹ã“ã¨ã¯ä¸€åˆ‡ã‚ã‚Šã¾ã›ã‚“ã®ã§ã€ã”å®‰å¿ƒãã ã•ã„ã€‚

ãªãŠã€è¨˜äº‹ã®æŠ•ç¨¿ã«ã‚ãŸã‚Šã€ä»¥ä¸‹ã®ç’°å¢ƒã§å‹•ä½œç¢ºèªã—ã¾ã—ãŸã€‚

- macOS Monterey 12.6.7
- Apple Swift 5.7

## å®Ÿè£…

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’`main.swift`ã¨ã—ã¦ä¿å­˜ã—ã¦ãã ã•ã„ã€‚

```swift
import SoundAnalysis

class ResultsObserver: NSObject, SNResultsObserving {
  func request(_ request: SNRequest, didProduce result: SNResult) {
    guard let result = result as? SNClassificationResult else {
      return
    }
    guard let classification = result.classifications.first else {
      return
    }

    let timeInSeconds = result.timeRange.start.seconds
    let formattedTime = String(format: "%.2f", timeInSeconds)

    print("Time: \(formattedTime)")

    let percent = classification.confidence * 100.0
    let percentString = String(format: "%.1f%%", percent)

    print("\(classification.identifier): \(percentString) confidence.\n")
  }
  func request(_ request: SNRequest, didFailWithError error: Error) {
    print("The analysis failed: \(error.localizedDescription)")
  }
  func requestDidComplete(_ request: SNRequest) {
    print("The request completed successfully!")
  }
}

func run() {
  if CommandLine.arguments.count < 2 {
    return
  }

  let audioFileURL = URL(fileURLWithPath: CommandLine.arguments[1])
  let resultsObserver = ResultsObserver()

  do {
    let classifySoundRequest = try SNClassifySoundRequest(classifierIdentifier: .version1)

    classifySoundRequest.windowDuration = CMTimeMake(value: 10, timescale: 10)

    let audioFileAnalyzer = try SNAudioFileAnalyzer(url: audioFileURL)

    try audioFileAnalyzer.add(classifySoundRequest, withObserver: resultsObserver)

    audioFileAnalyzer.analyze()
  } catch let error {
    print(error)
  }
}

run()
```

### è©¦é‹è»¢

ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚’é–‹ã„ã¦ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

```console
$ swift <éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹>
```

ä¸Šè¨˜ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ä¸€å®šã®æ™‚é–“ï¼ˆä»Šå›ã¯0.5ç§’ï¼‰ã”ã¨ã«åˆ†é¡ã‚’å®Ÿè¡Œã—ãŸçµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

### ï¼ˆå®Ÿè¡Œä¾‹ãã®1ï¼‰è©±ã—å£°ã®è­˜åˆ¥

macOSã«ã¯éŸ³å£°åˆæˆã‚³ãƒãƒ³ãƒ‰`say`ãŒæ­è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚ç”Ÿæˆã—ãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã©ã®ã‚ˆã†ã«è­˜åˆ¥ã•ã‚Œã‚‹ã‹è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

ã¾ãšã¯ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

```console
$ say -v Kyoko -o Kyoko.aiff 'ã“ã‚“ã«ã¡ã¯ã€ç§ã®åå‰ã¯Kyokoã§ã™ã€‚æ—¥æœ¬èªã®éŸ³å£°ã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚'
```

ä»¥ä¸‹ã®ã‚ˆã†ãªçµæœãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚

```console
$ swift main.swift Kyoko.aiff
Time: 0.00
speech: 92.4% confidence.

Time: 0.50
speech: 93.2% confidence.

Time: 1.00
speech: 93.3% confidence.

Time: 1.50
speech: 93.9% confidence.

Time: 2.00
speech: 94.4% confidence.

Time: 2.50
speech: 83.7% confidence.

Time: 3.00
speech: 85.3% confidence.

Time: 3.50
speech: 94.7% confidence.

Time: 4.00
speech: 92.8% confidence.

Time: 4.50
speech: 95.1% confidence.

The request completed successfully!
```
ç´ æ™´ã‚‰ã—ã„ã€æ­£ã—ã`speech`ï¼ˆè©±ã—å£°ï¼‰ã¨ã—ã¦è­˜åˆ¥ã•ã‚Œã¾ã—ãŸï¼

### ï¼ˆå®Ÿè¡Œä¾‹ãã®2ï¼‰ãƒ›ãƒ¯ã‚¤ãƒˆãƒã‚¤ã‚ºã®è­˜åˆ¥

æ¬¡ã¯ãƒ›ãƒ¯ã‚¤ãƒˆãƒã‚¤ã‚ºãŒã©ã®ã‚ˆã†ã«è­˜åˆ¥ã•ã‚Œã‚‹ã‹è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆã«ã¯soxã‚³ãƒãƒ³ãƒ‰ãŒä¾¿åˆ©ã§ã™ã€‚Homebrewã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚

```console
$ brew install sox
```

ãã‚Œã§ã¯ã€ãƒ›ãƒ¯ã‚¤ãƒˆãƒã‚¤ã‚ºãŒ10ç§’é–“è¨˜éŒ²ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯44.1 kHz / 2 ch / 16 bit PCMã¨ã—ã¾ã™ã€‚

```console
$ sox -n -r 44100 -c 2 -b 16 Noise.wav synth noise trim 0 10
```

ä»¥ä¸‹ã®ã‚ˆã†ãªçµæœãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚

```console
$ swift main.swift Noise.wav
Time: 0.00
waterfall: 43.1% confidence.

Time: 0.50
waterfall: 39.7% confidence.

Time: 1.00
waterfall: 47.3% confidence.

Time: 1.50
waterfall: 54.9% confidence.

Time: 2.00
waterfall: 50.9% confidence.

...

The request completed successfully!
```

`waterfall`ï¼ˆæ»ã®éŸ³ï¼‰ã¨ã—ã¦è­˜åˆ¥ã•ã‚Œã¾ã—ãŸã€‚ãŸã—ã‹ã«ãƒ›ãƒ¯ã‚¤ãƒˆãƒã‚¤ã‚ºã®ã€Œã‚µãƒ¼ã€ã¨ã„ã†éŸ³è‰²ã¯æ°´ãŒæµã‚Œè½ã¡ã‚‹éŸ³ã«ä¼¼ã¦ã„ã‚‹ã®ã§ã€æ‚ªããªã„çµæœã§ã™ã€‚

## ï¼ˆãŠã¾ã‘ï¼‰ä¸–ä»£åˆ¥iPhoneã®FLOPSæ¯”è¼ƒ

Appleè£½å“ã«ã¯ANEï¼ˆApple Neural Engineï¼‰ã¨ã‚ˆã°ã‚Œã‚‹æ©Ÿæ¢°å­¦ç¿’ã®ãŸã‚ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ãŒæ­è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚Core MLã‚’åˆ©ç”¨ã™ã‚‹éš›ã¯ANEã®æ€§èƒ½ã‚’è¸ã¾ãˆãŸæ¤œè¨ãŒå¿…è¦ã«ãªã‚Šã¾ã™ã€‚

å‚è€ƒã¾ã§ã«ã€iPhoneã«æ­è¼‰ã•ã‚ŒãŸANEã®FLOPSæ€§èƒ½ã‚’ç¤ºã—ã¾ã™ã€‚ä»¥ä¸‹ã¯[Apple Machine Learning Research](https://machinelearning.apple.com/research/neural-engine-transformers)ã‹ã‚‰ã®å¼•ç”¨ã§ã™ã€‚

| æ©Ÿç¨®å | ãƒãƒƒãƒ—ã®ä¸–ä»£ | FLOPS |
|:---|:---|:---|
| iPhone 13 Pro | A15 | 15.8 TFlops |
| iPhone 12 Pro | A14 | 11.66 TFlops |
| iPhone 11 Pro | A13 | 5.4 TFlops |
| iPhone XS | A12 |  5.4 TFlops |
\ iPhone X | A11 |  0.6 TFlops |

## å‚è€ƒè³‡æ–™

1. [Classifying Sounds in an Audio File - Apple Developer](https://developer.apple.com/documentation/soundanalysis/classifying_sounds_in_an_audio_file)
2. [SNClassifySoundRequest - Apple Developer](https://developer.apple.com/documentation/soundanalysis/snclassifysoundrequest)
3. [SNAudioFileAnalyzer - Apple Developer](https://developer.apple.com/documentation/soundanalysis/snaudiofileanalyzer)
4. [On-device APIs - Apple Developer](https://developer.apple.com/machine-learning/api/)
5. [Core ML - Apple Developer](https://developer.apple.com/documentation/coreml)
6. [Deploying Transformers on the Apple Neural Engine - Apple Machine Learning Research](https://machinelearning.apple.com/research/neural-engine-transformers)
