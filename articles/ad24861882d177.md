---
title: "PyTorchで書籍「ゼロから作るDeep Learning」のTwoLayerNetを実装する"
emoji: "🕌"
type: "tech"
topics: [PyTorch, Python, 機械学習, Apple]
published: false
---
## はじめに

書籍「ゼロから作るDeep Learning」を読み終えたので、次のステップとしてPyTorchの学習を進めています。まずは簡単な題材として、書籍の第4章で登場するTwoLayerNetを実装することにしました。

この記事ではMacBookでモデルの訓練と推論を試します。小さなモデルであれば訓練が数十秒で完了することを実験します。

## 環境

記事の投稿にあたり、以下の環境で動作確認しました。

- MacBook Pro（2021年に発売されたM1 PRO搭載マシン）
- macOS 12.7.1 Monterey
- Anaconda 23.7.4
- Python 3.11.5
- PyTorch 2.1.2

## PyTorchのインストール

ローカル環境でモデルの訓練とテストを行うため、[PyTorchのドキュメント](https://pytorch.org/get-started/locally/)に従ってPyTorchをインストールします。以下、Anacondaを利用してmacOSにインストールする場合の手順を抜粋します。

次のコマンドを実行します。

```console
conda install pytorch torchvision -c pytorch
```

正常にインストールできたか確認します。pytorchとtorchvisionのバージョンが表示されたら成功です。

```console
conda list | grep torch
pytorch                   2.1.2                  py3.11_0    pytorch
torchvision               0.16.2                py311_cpu    pytorch
```

以上でインストールは完了です。

続いてMPSが有効か確認します。python3コマンドを実行してインタプリタを起動し、次のコマンドを実行してください。Apple Siliconを搭載したマシンの場合はTrueが表示されます。

```console
>>> import torch
>>> torch.backends.mps.is_available()
True
```

なお、MPSが無効の場合はCPUが利用されます。時間はかかりますが、小さなモデルであれば訓練や推論は行えます。MPSが何者なのか、については記事の後半にまとめます。

## 実装

それでは、実装を示します。作業するディレクトリはどこでも構いませんが、ここでは`/tmp/torch`にて作業するものとします。

### モデルの訓練と保存

以下のコードを`train.py`として保存します。

```python
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

def get_available_device():
	if torch.cuda.is_available() :
		return 'cuda'
	elif torch.backends.mps.is_available():
		return 'mps'
	else:
		return 'cpu'

class TwoLayerNet(nn.Module):
	def __init__(self, input_size, hidden_size, output_size):
		super().__init__()
		self.flatten = nn.Flatten()
		self.layers = nn.Sequential(
			nn.Linear(input_size, hidden_size),
			nn.ReLU(),
			nn.Linear(hidden_size, output_size)
			# nn.Softmax(dim=1)
		)
	def forward(self, x):
		x = self.flatten(x)
		logits = self.layers(x)
		return logits

# どのハードウェアで訓練を行うか選択する。
device = get_available_device()

# モデルを作成する。
# 
# input_sizeには特徴量の次元を指定する。MNISTの画像は縦横28 pxの正方形なので28 * 28 = 784となる。
# hidden_sizeには隠れ層の重みの次元を指定する。この値は適当で構わないので、書籍に習って100を指定する。
# output_sizeには分類される数を指定する。MNISTのデータセットには0から9までの手書き数字の画像が含まれているため、output_sizeには10を指定する。
model = TwoLayerNet(input_size=784, hidden_size=100, output_size=10).to(device)

# 訓練データを読み込む。バッチのサイズは適当で構わないので、書籍に習って100を指定する。
batch_size = 100
training_datasets = datasets.MNIST(root="/tmp/torch/data", train=True, download=True, transform=ToTensor())
training_dataloader = DataLoader(training_datasets, batch_size=batch_size, shuffle=True)

# 損失関数として交差エントロピー誤差、オプティマイザとして確率的勾配降下法を利用する。Learning Rateなどのハイパーパラメータは適当で構わないが、ひとまず書籍にあわせる。
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)

# エポックの数は適当なので、訓練の進み具合に応じて増減させて構わない。
for epoch in range(25):
	running_loss = 0.0
	
	for i, data in enumerate(training_dataloader, 0):
		inputs, labels = data
		inputs, labels = inputs.to(device), labels.to(device)
		optimizer.zero_grad()
		outputs = model(inputs)
		loss = criterion(outputs, labels)
		loss.backward()
		optimizer.step()
		running_loss += loss.item()
		if i % 600 == 0:
			print(f'epoch={epoch + 1}, loss={running_loss:.5f}')
			running_loss = 0.0

# 訓練が終わったら、モデルを/tmp/torch/mnist.pthとして保存する。
torch.save(model.state_dict(), '/tmp/torch/mnist.pth')

print('Finished')
```

### モデルの読み込みと評価

以下のコードを`test.py`として保存します。

```python
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

def get_available_device():
	if torch.cuda.is_available() :
		return 'cuda'
	elif torch.backends.mps.is_available():
		return 'mps'
	else:
		return 'cpu'

class TwoLayerNet(nn.Module):
	def __init__(self, input_size, hidden_size, output_size):
		super().__init__()
		self.flatten = nn.Flatten()
		self.layers = nn.Sequential(
			nn.Linear(input_size, hidden_size),
			nn.ReLU(),
			nn.Linear(hidden_size, output_size)
			# nn.Softmax(dim=1)
		)
	def forward(self, x):
		x = self.flatten(x)
		logits = self.layers(x)
		return logits

device = get_available_device()
print(device)

model = TwoLayerNet(input_size=784, hidden_size=100, output_size=10).to(device)
model_path = './mnist.pth'
model.load_state_dict(torch.load(model_path))

batch_size = 100

test_datasets = datasets.MNIST(root="/tmp/torch/data", train=False, download=True, transform=ToTensor())
test_dataloader = DataLoader(test_datasets, batch_size=batch_size, shuffle=True)

correct = 0
total = 0

with torch.no_grad():
	for data in test_dataloader:
		inputs, labels = data
		inputs = inputs.to(device)
		labels = labels.to(device)
		outputs = model(inputs)
		_, predicted = torch.max(outputs.data, 1)
		total += labels.size(0)
		correct += (predicted == labels).sum().item()

print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')
```

## 動作確認

## （おまけ）MPSは何者だ？

Apple製デバイスにもGPUは搭載されています。MPS（Metal Performance Shaders）はGPUを利用するためのAPIです。機械学習のような行列の演算処理の高速化が期待できます。

とはいえ、NVIDIAのディスクリートGPUと比べると性能は劣ります。参考までにTFLOPSを示します。

- Apple M1: 2.6 TFLOPS
- Apple M1 PRO: 5.2 TFLOPS
- Apple M1 MAX: 10.4 TFLOPS
- NVIDIA GeForce RTX 4090: 82.4 TFLOPS

- [CPUもGPUも最高性能となったM1 ProとM1 Max、課題はアプリケーション対応 - PC Watch](https://pc.watch.impress.co.jp/docs/column/ubiq/1359506.html)
- [GeForce RTX 40完全解説 - シェーダの大増量にレイトレーシングの大幅機能強化など見どころのすべてを明らかに - 4Gamer.net](https://www.4gamer.net/games/656/G065603/20221010003/)

## （おまけ）PyTorchのチュートリアル
## 参考資料

