---
title: "視覚障害ユーザー向けの徒歩ナビアプリ開発断念までの記録"
emoji: "👋"
type: "tech"
topics: []
published: false
---
## はじめに

視覚障害ユーザー向けの徒歩ナビアプリ開発を検討し、断念するまでの記録です。

## アプリの動作イメージ

1. 目的地を選ぶ。この時点で目的地までの徒歩ルートデータが端末にダウンロードされ、以降インターネットが切断されても案内を続行できる。
2. 何らかの方法で正確な自己位置を推定する。
3. 交差点や曲がり角などに接近すると音声でユーザーに進む方向を伝達し、目的地へ案内する。

## 要件

**1. 屋内・屋外どこでも使える**

理由：視覚障害者は自分が屋内にいるのか屋外にいるのか区別できない場合がある。特に大型の商業施設など、屋内と屋外の境目が曖昧な場所では、そのような状況に陥る恐れがある。どちらか一方でしか使えない場合、自己位置の推定に失敗して誤った道案内をする恐れがある。

**2. スマホをポケットやカバンに収納していても利用できる**

理由：視覚障害者は歩行時に白杖を利用する。アプリ利用中は常に片手は使えない。そもそもスマホを片手に持って歩くのは危険。傘を持っている状況など、もう片方の手が自由に使えない状況もありえる。

## 既存アプリの調査

Microsoft Seeing AIアプリが屋内ナビゲーション機能を提供している。このアプリが最も徒歩ナビゲーションを正確に行える。アプリの挙動から想定される内部の実装は以下のとおり。

**1. 出発地点の探索は画像特徴量のみを用いて行われる。**

屋内ナビゲーションに限定しているのは、屋外は環境の変化が大きいためと想像できる。例えば同じ場所でも太陽が傾くと道に影ができる。そうすると、同じ場所なのに昼と夕方で異なる場所として認識される恐れがある。実際、Seeing AIアプリは出発地点の探索がうまく動作しないことがある。

**2. 徒歩案内を開始した後はカメラ映像とDead Reckoningのハイブリッドで自己位置を推定している。**

カメラのレンズを手で塞いでも案内が続行できることから、加速度センサーを用いたDead Reckoningとのハイブリッドであると想像できる。実際、カメラを手で塞いだ状態でスマホを激しく振ると現在位置が狂う。

## 実装の詳細検討

### GPSを用いた自己位置の推定

スマートフォンに搭載されたGPSを用いて絶対的な自己位置（緯度と経度）を推定する方式。

問題点

1. 精度が低い。10メートル単位で誤差が生じる。
2. 屋内や電波が届かない場所で自己位置が取得できないか、精度が低下する。

近所の交差点を調べてみると、交差点と交差点の間隔が10メートル未満の場所が想定より多いことに気がつく。GPSの分解能が足りないため、曲がるべき交差点を間違って指示する恐れがある。

### Dead Reckoning方式の自己位置推定

スマホに搭載された加速度センサーとジャイロを利用する方式。加速度の時間積分で移動距離と方向を求めて相対的な自己位置を推定する。

問題点

1. センサーのキャリブレーションが必要。静止している状態でもセンサーの値には変動がある。
2. デバイス組み込みの加速度センサーとジャイロはS / Nが低い。ノイズが多く値も不正確なため移動距離が求められない。

iOSのCore Motionフレームワークには歩行距離を求めるCMPedometerが含まれている。これは加速度の時間積分ではなく、単純にデバイスが振動していれば歩行状態として適当な推定値を計算しているだけなので、値は不正確。実際、iPhoneを手に持ってゆっくり振り続けると歩行状態としてカウントされてしまう。

そもそも、スマホをカバンに入れた状態で徒歩移動すると、カバンの中で激しく振動することになる。不正確な値がさらに不正確になるため、移動距離と方向を求める方法として適さない。

ある期間データを蓄えて、機械学習的なプローチでノイズを除去する方法も考えられる。しかし、徒歩ナビにはリアルタイムな情報が必要であり、この手法は適さない。

#### Apple WatchとAirPods

Apple WatchとAirPodsには加速度センサーとジャイロが搭載されている。Apple Watchは手首に、AirPodsは耳にデバイスが固定されるため、正確な値が取得できると想定される。

### 画像特徴量を用いた自己位置推定

スマホのカメラを用いる方式。事前に徒歩ルート周辺の景色を撮影した画像おを用意する。その画像とスマホのカメラで撮影された画像の特徴量を比べることで現在位置を推定する。

問題点

1. 徒歩ルート上の景色を撮影した画像を事前に準備する必要がある。また、ルートから外れた場合を想定して、周辺エリアの画像も準備する必要がある。
2. 柔軟性に欠ける。同じ場所で撮影された画像でも、太陽が傾いて道に影ができると、異なる場所として認識されてしまう。
3. スマホをポケットやカバンに収納している場合にカメラが利用できない。

iOSはVisionフレームワークで画像の類似度を計算できる。事前のデータ準備さえ克服できれば、最も確実な方式。

ただし、スマホを片手に持って歩く必要があり、アプリの要件を満たせない。ネックストラップでスマホを首かけする方法も考えられるが、実際に試してみるとスマホが揺れて適切な画像が得られない。
