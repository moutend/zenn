---
title: "PyTorchã§æ›¸ç±ã€Œã‚¼ãƒ­ã‹ã‚‰ä½œã‚‹Deep Learningã€ã®TwoLayerNetã‚’å®Ÿè£…ã™ã‚‹"
emoji: "ğŸ•Œ"
type: "tech"
topics: [PyTorch, Python, æ©Ÿæ¢°å­¦ç¿’, Apple]
published: false
---
## ã¯ã˜ã‚ã«

æ›¸ç±ã€Œ[ã‚¼ãƒ­ã‹ã‚‰ä½œã‚‹Deep Learning](https://www.oreilly.co.jp/books/9784873117584/)ã€ã‚’èª­ã¿çµ‚ãˆãŸã®ã§ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦PyTorchã®å­¦ç¿’ã‚’é€²ã‚ã¦ã„ã¾ã™ã€‚ã¾ãšã¯ç°¡å˜ãªé¡Œæã¨ã—ã¦ã€æ›¸ç±ã®ç¬¬4ç« ã§ç™»å ´ã™ã‚‹TwoLayerNetã‚’PyTorchã§å®Ÿè£…ã™ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸã€‚

ã“ã®è¨˜äº‹ã§ã¯MacBook Proã§ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨æ¨è«–ã‚’è©¦ã—ã¾ã™ã€‚å°ã•ãªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Œã°è¨“ç·´ãŒæ•°åç§’ã§å®Œäº†ã™ã‚‹ã“ã¨ã‚’å®Ÿé¨“ã—ã¾ã™ã€‚

## ç’°å¢ƒ

è¨˜äº‹ã®æŠ•ç¨¿ã«ã‚ãŸã‚Šã€ä»¥ä¸‹ã®ç’°å¢ƒã§å‹•ä½œç¢ºèªã—ã¾ã—ãŸã€‚

- MacBook Proï¼ˆ2021å¹´ã«ç™ºå£²ã•ã‚ŒãŸM1 PROæ­è¼‰æ©Ÿï¼‰
- macOS 12.7.1 Monterey
- Anaconda 23.7.4
- Python 3.11.5
- PyTorch 2.1.2

## PyTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨ãƒ†ã‚¹ãƒˆã‚’è¡Œã†ãŸã‚ã€[PyTorchã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://pytorch.org/get-started/locally/)ã«å¾“ã£ã¦PyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚ä»¥ä¸‹ã€Anacondaã‚’åˆ©ç”¨ã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å ´åˆã®æ‰‹é †ã‚’æŠœç²‹ã—ã¾ã™ã€‚

æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```console
conda install pytorch torchvision -c pytorch
```

æ­£å¸¸ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããŸã‹ç¢ºèªã—ã¾ã™ã€‚pytorchã¨torchvisionã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰æˆåŠŸã§ã™ã€‚

```console
conda list | grep torch
pytorch                   2.1.2                  py3.11_0    pytorch
torchvision               0.16.2                py311_cpu    pytorch
```

ä»¥ä¸Šã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¯å®Œäº†ã§ã™ã€‚

ç¶šã„ã¦MPSãŒæœ‰åŠ¹ã‹ç¢ºèªã—ã¾ã™ã€‚python3ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã‚¤ãƒ³ã‚¿ãƒ—ãƒªã‚¿ã‚’èµ·å‹•ã—ã€æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚Apple Siliconã‚’æ­è¼‰ã—ãŸãƒã‚·ãƒ³ã®å ´åˆã¯TrueãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

```console
>>> import torch
>>> torch.backends.mps.is_available()
True
```

ãªãŠã€MPSãŒç„¡åŠ¹ã®å ´åˆã¯CPUã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚æ™‚é–“ã¯ã‹ã‹ã‚Šã¾ã™ãŒã€å°ã•ãªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Œã°è¨“ç·´ã‚„æ¨è«–ã¯è¡Œãˆã¾ã™ã€‚MPSãŒä½•è€…ãªã®ã‹ã€ã«ã¤ã„ã¦ã¯è¨˜äº‹ã®å¾ŒåŠã«ã¦ç´¹ä»‹ã—ã¾ã™ã€‚

## å®Ÿè£…

ãã‚Œã§ã¯ã€å®Ÿè£…ã‚’ç¤ºã—ã¾ã™ã€‚ä½œæ¥­ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ã©ã“ã§ã‚‚æ§‹ã„ã¾ã›ã‚“ãŒã€ã“ã“ã§ã¯`/tmp/torch`ã«ã¦ä½œæ¥­ã™ã‚‹ã¨ä»®å®šã—ã¾ã™ã€‚

### ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨ä¿å­˜

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’`train.py`ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚

```python
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

class TwoLayerNet(nn.Module):
	def __init__(self, input_size, hidden_size, output_size):
		super().__init__()
		self.flatten = nn.Flatten()
		self.layers = nn.Sequential(
			nn.Linear(input_size, hidden_size),
			nn.ReLU(),
			nn.Linear(hidden_size, output_size)
		)
	def forward(self, x):
		x = self.flatten(x)
		logits = self.layers(x)
		return logits

def get_available_device():
	if torch.backends.mps.is_available():
		return 'mps'
	else:
		return 'cpu'

# ã©ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§è¨“ç·´ã‚’è¡Œã†ã‹é¸æŠã™ã‚‹ã€‚
device = get_available_device()

# ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ã€‚
# 
# input_sizeã«ã¯å…¥åŠ›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®æ¬¡å…ƒã‚’æŒ‡å®šã™ã‚‹ã€‚MNISTã®ç”»åƒã¯ç¸¦æ¨ª28 pxã®æ­£æ–¹å½¢ãªã®ã§ã€28 * 28 = 784ã‚’æŒ‡å®šã™ã‚‹ã€‚
# hidden_sizeã«ã¯éš ã‚Œå±¤ã®é‡ã¿ã®æ¬¡å…ƒã‚’æŒ‡å®šã™ã‚‹ã€‚ã“ã®å€¤ã¯é©å½“ã§æ§‹ã‚ãªã„ã®ã§ã€æ›¸ç±ã«ç¿’ã£ã¦100ã‚’æŒ‡å®šã™ã‚‹ã€‚
# output_sizeã«ã¯åˆ†é¡ã•ã‚Œã‚‹æ•°ã‚’æŒ‡å®šã™ã‚‹ã€‚MNISTã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯0ã‹ã‚‰9ã¾ã§ã®æ‰‹æ›¸ãæ•°å­—ã®ç”»åƒãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã€output_sizeã«ã¯10ã‚’æŒ‡å®šã™ã‚‹ã€‚
model = TwoLayerNet(input_size=784, hidden_size=100, output_size=10).to(device)

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ã€‚ãƒãƒƒãƒã®ã‚µã‚¤ã‚ºã¯é©å½“ã§æ§‹ã‚ãªã„ã®ã§ã€æ›¸ç±ã«ç¿’ã£ã¦100ã‚’æŒ‡å®šã™ã‚‹ã€‚
batch_size = 100
training_datasets = datasets.MNIST(root="./data", train=True, download=True, transform=ToTensor())
training_dataloader = DataLoader(training_datasets, batch_size=batch_size, shuffle=True)

# æå¤±é–¢æ•°ã¨ã—ã¦äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼èª¤å·®ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¨ã—ã¦ç¢ºç‡çš„å‹¾é…é™ä¸‹æ³•ã‚’åˆ©ç”¨ã™ã‚‹ã€‚Learning Rateãªã©ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯é©å½“ã§æ§‹ã‚ãªã„ãŒã€ã²ã¨ã¾ãšæ›¸ç±ã«ã‚ã‚ã›ã‚‹ã€‚
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)

# ã‚¨ãƒãƒƒã‚¯ã®æ•°ã¯é©å½“ãªã®ã§ã€è¨“ç·´ã®é€²ã¿å…·åˆã«å¿œã˜ã¦å¢—æ¸›ã•ã›ã¦æ§‹ã‚ãªã„ã€‚
for epoch in range(5):
	running_loss = 0.0
	
	for i, data in enumerate(training_dataloader, 0):
		inputs, labels = data
		inputs, labels = inputs.to(device), labels.to(device)
		optimizer.zero_grad()
		outputs = model(inputs)
		loss = criterion(outputs, labels)
		loss.backward()
		optimizer.step()
		running_loss += loss.item()
		if i % 600 == 0:
			print(f'epoch={epoch + 1}, loss={running_loss:.5f}')
			running_loss = 0.0

# è¨“ç·´ãŒçµ‚ã‚ã£ãŸã‚‰ã€ãƒ¢ãƒ‡ãƒ«ã‚’mnist.pthã¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ã€‚
torch.save(model.state_dict(), './mnist.pth')

print("\nFinished!")
```

### ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã¨è©•ä¾¡

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’`test.py`ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚

```python
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

class TwoLayerNet(nn.Module):
	def __init__(self, input_size, hidden_size, output_size):
		super().__init__()
		self.flatten = nn.Flatten()
		self.layers = nn.Sequential(
			nn.Linear(input_size, hidden_size),
			nn.ReLU(),
			nn.Linear(hidden_size, output_size)
			# nn.Softmax(dim=1)
		)
	def forward(self, x):
		x = self.flatten(x)
		logits = self.layers(x)
		return logits

def get_available_device():
	if torch.backends.mps.is_available():
		return 'mps'
	else:
		return 'cpu'

device = get_available_device()

# è¨“ç·´æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã€‚
model = TwoLayerNet(input_size=784, hidden_size=100, output_size=10).to(device)
model_path = './mnist.pth'
model.load_state_dict(torch.load(model_path))

# ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ã€‚
batch_size = 100
test_datasets = datasets.MNIST(root="./data", train=False, download=True, transform=ToTensor())
test_dataloader = DataLoader(test_datasets, batch_size=batch_size, shuffle=True)

# ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹ã€‚
correct = 0
total = 0

with torch.no_grad():
	for data in test_dataloader:
		inputs, labels = data
		inputs = inputs.to(device)
		labels = labels.to(device)
		outputs = model(inputs)
		_, predicted = torch.max(outputs.data, 1)
		total += labels.size(0)
		correct += (predicted == labels).sum().item()

print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')
```

## å‹•ä½œç¢ºèª

ãã‚Œã§ã¯å‹•ä½œç¢ºèªã‚’è¡Œã„ã¾ã—ã‚‡ã†ã€‚ã¾ãšã¯ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‹ã‚‰ã§ã™ã€‚

æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚ï¼ˆåˆå›ã¯ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚å®Œäº†ã¾ã§æ•°åˆ†ã‹ã‹ã‚Šã¾ã™ï¼‰

```console
python3 train.py
```

è¨“ç·´ã¯10ç§’ã»ã©ã§å®Œäº†ã—ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚ˆã†ã«æå¤±ï¼ˆlossï¼‰ãŒå¾ã€…ã«å°ã•ããªã£ã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã§ããŸã‚‰æˆåŠŸã§ã™ã€‚

```console
epoch=1, loss=2.28737
epoch=2, loss=0.11533
epoch=3, loss=0.09539
epoch=4, loss=0.09099
epoch=5, loss=0.06506

Finished!
```

ã€è¨“ç·´ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã¾ã—ã‚‡ã†ã€‚æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

```console
python3 test.py
```

çµæœã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ã“ã®çµæœã¨å…¨ãåŒã˜ã«ãªã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ãŒã€ãŠãŠã‚€ã­95 %ä»¥ä¸Šã«ãªã‚‹ã¯ãšã§ã™ã€‚

```console
Accuracy of the network on the 10000 test images: 97.65 %
```

ä»¥ä¸Šã§å‹•ä½œç¢ºèªã¯å®Œäº†ã§ã™ï¼

## ï¼ˆãŠã¾ã‘ï¼‰MPSã¯ä½•è€…ã ï¼Ÿ

Appleè£½ãƒ‡ãƒã‚¤ã‚¹ã«ã‚‚GPUã¯æ­è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚MPSï¼ˆMetal Performance Shadersï¼‰ã¯GPUã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã®APIã§ã™ã€‚è¡Œåˆ—ã®æ¼”ç®—ã‚’å¤šç”¨ã™ã‚‹å‡¦ç†ã®é«˜é€ŸåŒ–ãŒæœŸå¾…ã§ãã¾ã™ã€‚

ä½™è«‡ã«ãªã‚Šã¾ã™ãŒã€Appleã®MPSç´¹ä»‹ãƒšãƒ¼ã‚¸ã«ã¯PyTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚³ãƒãƒ³ãƒ‰ãŒæ²è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚å†…å®¹ãŒå¤ã„ã®ã§ãã®éƒ¨åˆ†ã¯ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚

- [Accelerated PyTorch training on Mac - Apple Developer](https://developer.apple.com/metal/pytorch/)

## ï¼ˆãŠã¾ã‘ï¼‰PyTorchã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã€ã©ã®é †ç•ªã§èª­ã¿é€²ã‚ã‚‹ã‹ï¼Ÿ

PyTorchã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã¯åˆå­¦è€…å‘ã‘ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ãŒå¤§é‡ã«ç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚

## å‚è€ƒè³‡æ–™

