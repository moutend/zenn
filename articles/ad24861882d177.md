---
title: "PyTorchã§æ›¸ç±ã€Œã‚¼ãƒ­ã‹ã‚‰ä½œã‚‹Deep Learningã€ã®TwoLayerNetã‚’å®Ÿè£…ã™ã‚‹"
emoji: "ğŸ•Œ"
type: "tech"
topics: [PyTorch, Python, æ©Ÿæ¢°å­¦ç¿’, Apple]
published: false
---
## ã¯ã˜ã‚ã«

æ›¸ç±ã€Œã‚¼ãƒ­ã‹ã‚‰ä½œã‚‹Deep Learningã€ã‚’èª­ã¿çµ‚ãˆãŸã®ã§ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦PyTorchã®å­¦ç¿’ã‚’é€²ã‚ã¦ã„ã¾ã™ã€‚ã¾ãšã¯ç°¡å˜ãªé¡Œæã¨ã—ã¦ã€æ›¸ç±ã®ç¬¬4ç« ã§ç™»å ´ã™ã‚‹TwoLayerNetã‚’å®Ÿè£…ã™ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸã€‚

ã“ã®è¨˜äº‹ã§ã¯MacBookã§ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨æ¨è«–ã‚’è©¦ã—ã¾ã™ã€‚å°ã•ãªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Œã°è¨“ç·´ãŒæ•°åç§’ã§å®Œäº†ã™ã‚‹ã“ã¨ã‚’å®Ÿé¨“ã—ã¾ã™ã€‚

## ç’°å¢ƒ

è¨˜äº‹ã®æŠ•ç¨¿ã«ã‚ãŸã‚Šã€ä»¥ä¸‹ã®ç’°å¢ƒã§å‹•ä½œç¢ºèªã—ã¾ã—ãŸã€‚

- MacBook Proï¼ˆ2021å¹´ã«ç™ºå£²ã•ã‚ŒãŸM1 PROæ­è¼‰ãƒã‚·ãƒ³ï¼‰
- macOS 12.7.1 Monterey
- Anaconda 23.7.4
- Python 3.11.5
- PyTorch 2.1.2

## PyTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨ãƒ†ã‚¹ãƒˆã‚’è¡Œã†ãŸã‚ã€[PyTorchã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://pytorch.org/get-started/locally/)ã«å¾“ã£ã¦PyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚ä»¥ä¸‹ã€Anacondaã‚’åˆ©ç”¨ã—ã¦macOSã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å ´åˆã®æ‰‹é †ã‚’æŠœç²‹ã—ã¾ã™ã€‚

æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```console
conda install pytorch torchvision -c pytorch
```

æ­£å¸¸ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããŸã‹ç¢ºèªã—ã¾ã™ã€‚pytorchã¨torchvisionã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰æˆåŠŸã§ã™ã€‚

```console
conda list | grep torch
pytorch                   2.1.2                  py3.11_0    pytorch
torchvision               0.16.2                py311_cpu    pytorch
```

ä»¥ä¸Šã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¯å®Œäº†ã§ã™ã€‚

ç¶šã„ã¦MPSãŒæœ‰åŠ¹ã‹ç¢ºèªã—ã¾ã™ã€‚python3ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã‚¤ãƒ³ã‚¿ãƒ—ãƒªã‚¿ã‚’èµ·å‹•ã—ã€æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚Apple Siliconã‚’æ­è¼‰ã—ãŸãƒã‚·ãƒ³ã®å ´åˆã¯TrueãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

```console
>>> import torch
>>> torch.backends.mps.is_available()
True
```

ãªãŠã€MPSãŒç„¡åŠ¹ã®å ´åˆã¯CPUãŒåˆ©ç”¨ã•ã‚Œã¾ã™ã€‚æ™‚é–“ã¯ã‹ã‹ã‚Šã¾ã™ãŒã€å°ã•ãªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Œã°è¨“ç·´ã‚„æ¨è«–ã¯è¡Œãˆã¾ã™ã€‚MPSãŒä½•è€…ãªã®ã‹ã€ã«ã¤ã„ã¦ã¯è¨˜äº‹ã®å¾ŒåŠã«ã¾ã¨ã‚ã¾ã™ã€‚

## å®Ÿè£…

ãã‚Œã§ã¯ã€å®Ÿè£…ã‚’ç¤ºã—ã¾ã™ã€‚ä½œæ¥­ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ã©ã“ã§ã‚‚æ§‹ã„ã¾ã›ã‚“ãŒã€ã“ã“ã§ã¯`/tmp/torch`ã«ã¦ä½œæ¥­ã™ã‚‹ã‚‚ã®ã¨ã—ã¾ã™ã€‚

### ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨ä¿å­˜

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’`train.py`ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚

```python
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

def get_available_device():
	if torch.cuda.is_available() :
		return 'cuda'
	elif torch.backends.mps.is_available():
		return 'mps'
	else:
		return 'cpu'

class TwoLayerNet(nn.Module):
	def __init__(self, input_size, hidden_size, output_size):
		super().__init__()
		self.flatten = nn.Flatten()
		self.layers = nn.Sequential(
			nn.Linear(input_size, hidden_size),
			nn.ReLU(),
			nn.Linear(hidden_size, output_size)
			# nn.Softmax(dim=1)
		)
	def forward(self, x):
		x = self.flatten(x)
		logits = self.layers(x)
		return logits

# ã©ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§è¨“ç·´ã‚’è¡Œã†ã‹é¸æŠã™ã‚‹ã€‚
device = get_available_device()

# ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ã€‚
# 
# input_sizeã«ã¯ç‰¹å¾´é‡ã®æ¬¡å…ƒã‚’æŒ‡å®šã™ã‚‹ã€‚MNISTã®ç”»åƒã¯ç¸¦æ¨ª28 pxã®æ­£æ–¹å½¢ãªã®ã§28 * 28 = 784ã¨ãªã‚‹ã€‚
# hidden_sizeã«ã¯éš ã‚Œå±¤ã®é‡ã¿ã®æ¬¡å…ƒã‚’æŒ‡å®šã™ã‚‹ã€‚ã“ã®å€¤ã¯é©å½“ã§æ§‹ã‚ãªã„ã®ã§ã€æ›¸ç±ã«ç¿’ã£ã¦100ã‚’æŒ‡å®šã™ã‚‹ã€‚
# output_sizeã«ã¯åˆ†é¡ã•ã‚Œã‚‹æ•°ã‚’æŒ‡å®šã™ã‚‹ã€‚MNISTã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯0ã‹ã‚‰9ã¾ã§ã®æ‰‹æ›¸ãæ•°å­—ã®ç”»åƒãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã€output_sizeã«ã¯10ã‚’æŒ‡å®šã™ã‚‹ã€‚
model = TwoLayerNet(input_size=784, hidden_size=100, output_size=10).to(device)

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ã€‚ãƒãƒƒãƒã®ã‚µã‚¤ã‚ºã¯é©å½“ã§æ§‹ã‚ãªã„ã®ã§ã€æ›¸ç±ã«ç¿’ã£ã¦100ã‚’æŒ‡å®šã™ã‚‹ã€‚
batch_size = 100
training_datasets = datasets.MNIST(root="/tmp/torch/data", train=True, download=True, transform=ToTensor())
training_dataloader = DataLoader(training_datasets, batch_size=batch_size, shuffle=True)

# æå¤±é–¢æ•°ã¨ã—ã¦äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼èª¤å·®ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¨ã—ã¦ç¢ºç‡çš„å‹¾é…é™ä¸‹æ³•ã‚’åˆ©ç”¨ã™ã‚‹ã€‚Learning Rateãªã©ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯é©å½“ã§æ§‹ã‚ãªã„ãŒã€ã²ã¨ã¾ãšæ›¸ç±ã«ã‚ã‚ã›ã‚‹ã€‚
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)

# ã‚¨ãƒãƒƒã‚¯ã®æ•°ã¯é©å½“ãªã®ã§ã€è¨“ç·´ã®é€²ã¿å…·åˆã«å¿œã˜ã¦å¢—æ¸›ã•ã›ã¦æ§‹ã‚ãªã„ã€‚
for epoch in range(25):
	running_loss = 0.0
	
	for i, data in enumerate(training_dataloader, 0):
		inputs, labels = data
		inputs, labels = inputs.to(device), labels.to(device)
		optimizer.zero_grad()
		outputs = model(inputs)
		loss = criterion(outputs, labels)
		loss.backward()
		optimizer.step()
		running_loss += loss.item()
		if i % 600 == 0:
			print(f'epoch={epoch + 1}, loss={running_loss:.5f}')
			running_loss = 0.0

# è¨“ç·´ãŒçµ‚ã‚ã£ãŸã‚‰ã€ãƒ¢ãƒ‡ãƒ«ã‚’/tmp/torch/mnist.pthã¨ã—ã¦ä¿å­˜ã™ã‚‹ã€‚
torch.save(model.state_dict(), '/tmp/torch/mnist.pth')

print('Finished')
```

### ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã¨è©•ä¾¡

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’`test.py`ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚

```python
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

def get_available_device():
	if torch.cuda.is_available() :
		return 'cuda'
	elif torch.backends.mps.is_available():
		return 'mps'
	else:
		return 'cpu'

class TwoLayerNet(nn.Module):
	def __init__(self, input_size, hidden_size, output_size):
		super().__init__()
		self.flatten = nn.Flatten()
		self.layers = nn.Sequential(
			nn.Linear(input_size, hidden_size),
			nn.ReLU(),
			nn.Linear(hidden_size, output_size)
			# nn.Softmax(dim=1)
		)
	def forward(self, x):
		x = self.flatten(x)
		logits = self.layers(x)
		return logits

device = get_available_device()
print(device)

model = TwoLayerNet(input_size=784, hidden_size=100, output_size=10).to(device)
model_path = './mnist.pth'
model.load_state_dict(torch.load(model_path))

batch_size = 100

test_datasets = datasets.MNIST(root="/tmp/torch/data", train=False, download=True, transform=ToTensor())
test_dataloader = DataLoader(test_datasets, batch_size=batch_size, shuffle=True)

correct = 0
total = 0

with torch.no_grad():
	for data in test_dataloader:
		inputs, labels = data
		inputs = inputs.to(device)
		labels = labels.to(device)
		outputs = model(inputs)
		_, predicted = torch.max(outputs.data, 1)
		total += labels.size(0)
		correct += (predicted == labels).sum().item()

print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')
```

## å‹•ä½œç¢ºèª

## ï¼ˆãŠã¾ã‘ï¼‰MPSã¯ä½•è€…ã ï¼Ÿ

Appleè£½ãƒ‡ãƒã‚¤ã‚¹ã«ã‚‚GPUã¯æ­è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚MPSï¼ˆMetal Performance Shadersï¼‰ã¯GPUã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã®APIã§ã™ã€‚æ©Ÿæ¢°å­¦ç¿’ã®ã‚ˆã†ãªè¡Œåˆ—ã®æ¼”ç®—å‡¦ç†ã®é«˜é€ŸåŒ–ãŒæœŸå¾…ã§ãã¾ã™ã€‚

ã¨ã¯ã„ãˆã€NVIDIAã®ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ¼ãƒˆGPUã¨æ¯”ã¹ã‚‹ã¨æ€§èƒ½ã¯åŠ£ã‚Šã¾ã™ã€‚å‚è€ƒã¾ã§ã«TFLOPSã‚’ç¤ºã—ã¾ã™ã€‚

- Apple M1: 2.6 TFLOPS
- Apple M1 PRO: 5.2 TFLOPS
- Apple M1 MAX: 10.4 TFLOPS
- NVIDIA GeForce RTX 4090: 82.4 TFLOPS

- [CPUã‚‚GPUã‚‚æœ€é«˜æ€§èƒ½ã¨ãªã£ãŸM1 Proã¨M1 Maxã€èª²é¡Œã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œ - PC Watch](https://pc.watch.impress.co.jp/docs/column/ubiq/1359506.html)
- [GeForce RTX 40å®Œå…¨è§£èª¬ - ã‚·ã‚§ãƒ¼ãƒ€ã®å¤§å¢—é‡ã«ãƒ¬ã‚¤ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã®å¤§å¹…æ©Ÿèƒ½å¼·åŒ–ãªã©è¦‹ã©ã“ã‚ã®ã™ã¹ã¦ã‚’æ˜ã‚‰ã‹ã« - 4Gamer.net](https://www.4gamer.net/games/656/G065603/20221010003/)

## ï¼ˆãŠã¾ã‘ï¼‰PyTorchã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
## å‚è€ƒè³‡æ–™

