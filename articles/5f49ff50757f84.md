---
title: "（SwiftUI）Core MLで画像分類を試す"
emoji: "🦁"
type: "tech"
topics: [Apple, iOS, Swift, "Core ML", 機械学習]
published: false
---
## はじめに

SwiftUIでCore MLを利用して画像分類を行うサンプルアプリを作成しました。以下のリポジトリで公開していますので、試してみてください。

- [github.com/moutend/ClassifyingImagesWithSwiftUI](https://github.com/moutend/ClassifyingImagesWithSwiftUI)

## 推論にかかる時間の測定結果

参考までに、推論にかかる時間の測定結果を記載します。サンプルアプリで利用しているモデルはMobileNetV2の16 bit float版です。

- [Models - Machine Learning - Apple Developer](https://developer.apple.com/machine-learning/models/)

動作検証は以下の実機で行いました。

- iPhone 15 Pro
- iPhone 13
- iPhone SE 第2世代

以下の結果は各々10回の推論を行った中央値です。

- iPhone 15 Pro: 39 ms
- iPhone 13: 70 ms
- iPhone SE 第2世代: 134 ms

**補足**

- 上記の結果はバッテリーを100 %まで充電し、他のアプリはすべて閉じた状態で測定した結果です。バッテリーの残量やバックグラウンドで起動しているアプリなど、リソースの状態によってパフォーマンスは変化する可能性があります。
- アプリ初回起動時はMLインスタンス生成のため推論にかかる時間が大幅に伸びます。
    - iPhone 15 Pro: 350 ms前後
    - iPhone 13: 660 ms前後
    - iPhone SE 第2世代: 900 ms前後
    - この結果から、デバイスの世代に関係なく初回の推論は中央値の10倍ほど時間がかかると想定できます。

## 参考資料

1. [Classifying Images with Vision and Core ML - Apple Developer Documentation](https://developer.apple.com/documentation/coreml/model_integration_samples/classifying_images_with_vision_and_core_ml)
2. [Integrating a Core ML Model into Your App - Apple Developer Documentation](https://developer.apple.com/documentation/coreml/integrating-a-core-ml-model-into-your-app)
