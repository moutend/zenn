---
title: "PyTorchã§æ›¸ç±ã€Œã‚¼ãƒ­ã‹ã‚‰ä½œã‚‹Deep Learningã€ã®TwoLayerNetã‚’å®Ÿè£…ã™ã‚‹"
emoji: "ğŸ•Œ"
type: "tech"
topics: [PyTorch, Python, æ©Ÿæ¢°å­¦ç¿’]
published: false
---
## ã¯ã˜ã‚ã«

æ›¸ç±ã€Œã‚¼ãƒ­ã‹ã‚‰ä½œã‚‹Deep Learningã€ã‚’èª­ã¿çµ‚ãˆãŸã®ã§ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦PyTorchã®å­¦ç¿’ã‚’é€²ã‚ã¦ã„ã¾ã™ã€‚ã¾ãšã¯ç°¡å˜ãªé¡Œæã¨ã—ã¦ã€æ›¸ç±ã®ç¬¬4ç« ã§ç™»å ´ã™ã‚‹TwoLayerNetã‚’å®Ÿè£…ã™ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸã€‚

## ç’°å¢ƒ

è¨˜äº‹ã®æŠ•ç¨¿ã«ã‚ãŸã‚Šã€ä»¥ä¸‹ã®ç’°å¢ƒã§å‹•ä½œç¢ºèªã—ã¾ã—ãŸã€‚

- macOS 12.7.1 Monterey
- Anaconda 23.7.4
- Python 3.11.5

## ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨ä¿å­˜

```python
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

def get_available_device():
	if torch.cuda.is_available() :
		return 'cuda'
	elif torch.backends.mps.is_available():
		return 'mps'
	else:
		return 'cpu'

class TwoLayerNet(nn.Module):
	def __init__(self, input_size, hidden_size, output_size):
		super().__init__()
		self.flatten = nn.Flatten()
		self.layers = nn.Sequential(
			nn.Linear(input_size, hidden_size),
			nn.ReLU(),
			nn.Linear(hidden_size, output_size)
			# nn.Softmax(dim=1)
		)
	def forward(self, x):
		x = self.flatten(x)
		logits = self.layers(x)
		return logits

# ã©ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§è¨“ç·´ã‚’è¡Œã†ã‹é¸æŠã™ã‚‹ã€‚macOS 12.3ä»¥é™ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã‚ã‚Œã°Metal Performance Shadersï¼ˆ'mps'ï¼‰ãŒé¸æŠã•ã‚Œã‚‹ã€‚
device = get_available_device()

# ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ã€‚
# 
# input_sizeã«ã¯ç‰¹å¾´é‡ã®æ¬¡å…ƒã‚’æŒ‡å®šã™ã‚‹ã€‚MNISTã®ç”»åƒã¯ç¸¦æ¨ª28 pxã®æ­£æ–¹å½¢ãªã®ã§28 * 28 = 784ã¨ãªã‚‹ã€‚
# hidden_sizeã«ã¯éš ã‚Œå±¤ã®é‡ã¿ã®æ¬¡å…ƒã‚’æŒ‡å®šã™ã‚‹ã€‚ã“ã®å€¤ã¯é©å½“ã§æ§‹ã‚ãªã„ã®ã§ã€æ›¸ç±ã«ç¿’ã£ã¦100ã‚’æŒ‡å®šã™ã‚‹ã€‚
# output_sizeã«ã¯åˆ†é¡ã•ã‚Œã‚‹æ•°ã‚’æŒ‡å®šã™ã‚‹ã€‚MNISTã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯0ã‹ã‚‰9ã¾ã§ã®æ‰‹æ›¸ãæ•°å­—10ç¨®é¡ãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã€output_sizeã«ã¯10ã‚’æŒ‡å®šã™ã‚‹ã€‚
model = TwoLayerNet(input_size=784, hidden_size=100, output_size=10).to(device)

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ã€‚ãƒãƒƒãƒã®ã‚µã‚¤ã‚ºã¯é©å½“ã§æ§‹ã‚ãªã„ã®ã§ã€æ›¸ç±ã«ç¿’ã£ã¦100ã‚’æŒ‡å®šã™ã‚‹ã€‚
batch_size = 100
training_datasets = datasets.MNIST(root="/tmp/torch/data", train=True, download=True, transform=ToTensor())
training_dataloader = DataLoader(training_datasets, batch_size=batch_size, shuffle=True)

# æå¤±é–¢æ•°ã¨ã—ã¦äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼èª¤å·®ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¨ã—ã¦ç¢ºç‡çš„å‹¾é…é™ä¸‹æ³•ã‚’åˆ©ç”¨ã™ã‚‹ã€‚Learning Rateãªã©ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯é©å½“ã§æ§‹ã‚ãªã„ã€‚
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)

# ã‚¨ãƒãƒƒã‚¯ã®æ•°ã¯é©å½“ãªã®ã§è¨“ç·´ã®é€²ã¿å…·åˆã«å¿œã˜ã¦å¢—æ¸›ã•ã›ã¦ãã ã•ã„ã€‚
for epoch in range(25):
	running_loss = 0.0
	
	for i, data in enumerate(training_dataloader, 0):
		inputs, labels = data
		inputs, labels = inputs.to(device), labels.to(device)
		optimizer.zero_grad()
		outputs = model(inputs)
		loss = criterion(outputs, labels)
		loss.backward()
		optimizer.step()
		running_loss += loss.item()
		if i % 600 == 0:
			print(f'epoch={epoch + 1}, loss={running_loss:.5f}')
			running_loss = 0.0

torch.save(model.state_dict(), '/tmp/torch/mnist.pth')

print('Finished')
```

## ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ

```python
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

def get_available_device():
	if torch.cuda.is_available() :
		return 'cuda'
	elif torch.backends.mps.is_available():
		return 'mps'
	else:
		return 'cpu'

class TwoLayerNet(nn.Module):
	def __init__(self, input_size, hidden_size, output_size):
		super().__init__()
		self.flatten = nn.Flatten()
		self.layers = nn.Sequential(
			nn.Linear(input_size, hidden_size),
			nn.ReLU(),
			nn.Linear(hidden_size, output_size)
			# nn.Softmax(dim=1)
		)
	def forward(self, x):
		x = self.flatten(x)
		logits = self.layers(x)
		return logits

device = get_available_device()
print(device)

model = TwoLayerNet(input_size=784, hidden_size=100, output_size=10).to(device)
model_path = './mnist.pth'
model.load_state_dict(torch.load(model_path))

batch_size = 100

test_datasets = datasets.MNIST(root="/tmp/torch/data", train=False, download=True, transform=ToTensor())
test_dataloader = DataLoader(test_datasets, batch_size=batch_size, shuffle=True)

correct = 0
total = 0

with torch.no_grad():
	for data in test_dataloader:
		inputs, labels = data
		inputs = inputs.to(device)
		labels = labels.to(device)
		outputs = model(inputs)
		_, predicted = torch.max(outputs.data, 1)
		total += labels.size(0)
		correct += (predicted == labels).sum().item()

print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')
```

## ï¼ˆãŠã¾ã‘ï¼‰PyTorchã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«

## å‚è€ƒè³‡æ–™

