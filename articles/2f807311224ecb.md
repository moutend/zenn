---
title: "iPhone実機でAppleのFastVLMを試す"
emoji: "😸"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: [Apple, iPhone, iOS, LLM]
published: false
---
## はじめに

2025年5月15日にAppleが公開したVision Language ModelであるFastVLMをiPhone実機で試したのでメモします。大雑把に説明するとVLMというのは画像の内容をテキストで説明してくれるモデルです。  

- [FastVLM：Apple製 超高速視覚言語モデル](https://fastvlm.net/ja)

GitHubのリポジトリは以下です。すぐに試せるサンプルアプリも含まれています。  

https://github.com/apple/ml-fastvlm

## （補足）アプリのビルドについて

最新のXcode 16.4 (16F6)を利用している場合、そのままではビルドが失敗します。以下のように修正してください。  

- app/FastVLM.xcodeprojを開き、画面左のプロジェクトナビゲーターでFastVLMを選択します。
- ターゲットリストでFastVLMを選び、Info / Build Settings / Package Dependenciesタブメニューを表示させます。ここでPackage Dependenciesタブを選択します。
- 3つの依存パッケージが設定されているので、以下のように2箇所変更します。
    - mlx-librariesのバージョン指定をExact Version (2.21.2)に変更
    - swift-transformersのバージョン指定をExact Version (0.1.18)に変更

あとはapp/README.mdに従って操作するだけでビルドが成功します。M1 PROチップを搭載したMacBook Pro 2021年モデルではビルド完了まで1分ほどかかりました。  
ちなみに、この件についてはIssueが建てられているので、いずれ修正されるかもしれません。放置されている様子を見ると、優先度は低そうですが。  

https://github.com/apple/ml-fastvlm/issues/37

## 結果

モバイル向けとされている0.5Bモデルで試した結果をまとめます。  

- iPhone 15 Pro: 画像の内容によるがTTFT 2,000 ms前後でテキスト生成可能だった。回答全文の生成完了までは数百msオーダー。
- iPhone SE 第2世代: アプリ起動後数秒でクラッシュした。

## 所感

超高速という宣伝は嘘ではないしモバイル端末で動作はしていますが、今のところ実用から程遠い印象です。  

- 対応機種が限られる。最小の0.5Bモデルですら、まともに動くのはiPhone 15 Proシリーズ以降に限定される。
- バッテリーの消費と発熱が大きすぎる。長時間稼働でサーマルスロットリングが発生して動作が不安定 or クラッシュする恐れあり。
- 特に発熱がひどい。実機背面の温度は計測できていないが、アプリ起動後数十秒で火傷しそうなほど熱くなる。
- 画像分類やOCR、人物・手のジェスチャ認識タスクなどは既存のVisionフレームワークを利用する方がよい。iPhone SE 第2世代でも消費電力が小さく高速に動作する。

Appleはリアルタイムな画像認識によるアクセシビリティ関連アプリの開発が広がる可能性に言及していますが、そのような用途には適さない印象です。モデルの性能うんぬん以前にバッテリーの消費と発熱が激しすぎます。例えば視覚障害を想定した道案内アプリを作るとして、発熱が原因でアプリが頻繁にクラッシュしていては役に立ちません。  
個人的にはGoogle Gemini Flashの代わりに、完全オフラインで動作するモデルとして期待していたのですが、残念ながらモバイル端末での利用は非現実的です。DSP的な専用プロセッサーが登場しない限り、少なくともあと3、4年先の世代になるまでハードウェアの性能向上を待つことになりそうです。  
